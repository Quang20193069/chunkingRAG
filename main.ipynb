{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"document.pdf\"\n",
    "OUTPUT_DIR = \"pdf_chunks\"\n",
    "CHROMA_DB_DIR = \"chroma_db\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(doc, img_info, page_number):\n",
    "    xref = img_info[0]\n",
    "    base_image = doc.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "    img_ext = base_image[\"ext\"]\n",
    "    img_filename = f\"page_{page_number}_img_{xref}.{img_ext}\"\n",
    "    img_path = os.path.join(OUTPUT_DIR, img_filename)\n",
    "    with open(img_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks_from_page(blocks, images, page_number):\n",
    "    chunks = []\n",
    "    current_chunk = {\"text\": \"\", \"table\": None, \"image_path\": None, \"image_caption\": None, \"y\": None}\n",
    "    last_y1 = 0\n",
    "    chunk_y_positions = []\n",
    "\n",
    "    for block in sorted(blocks, key=lambda b: b[1]):  # sort by y0\n",
    "        x0, y0, x1, y1, text, block_no = block\n",
    "        text = text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        if current_chunk[\"y\"] is None:\n",
    "            current_chunk[\"y\"] = y0\n",
    "\n",
    "        # Ngắt chunk nếu khoảng cách giữa 2 block quá lớn\n",
    "        if y0 - last_y1 > 40 and current_chunk[\"text\"]:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = {\"text\": \"\", \"table\": None, \"image_path\": None, \"image_caption\": None, \"y\": y0}\n",
    "\n",
    "        current_chunk[\"text\"] += text + \"\\n\"\n",
    "        last_y1 = y1\n",
    "\n",
    "    if current_chunk[\"text\"]:\n",
    "        chunks.append(current_chunk)\n",
    "    # print(len(chunks))\n",
    "    # Gắn ảnh vào chunk gần nhất\n",
    "    if chunks:\n",
    "        for img_path, img_y in images:\n",
    "            closest_chunk = min(chunks, key=lambda c: abs(c.get(\"y\", 0) - img_y))\n",
    "            closest_chunk[\"image_path\"] = img_path\n",
    "            closest_chunk[\"image_caption\"] = \"Ảnh minh hoạ từ trang PDF.\"\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_chunks = []\n",
    "\n",
    "    for page_number in range(len(doc)):\n",
    "        page = doc[page_number]\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        # Get block info: x0, y0, x1, y1, text, block_no\n",
    "        block_info = [\n",
    "            (b[0], b[1], b[2], b[3], b[4], i) for i, b in enumerate(blocks)\n",
    "        ]\n",
    "\n",
    "        # Get image info\n",
    "        img_list = page.get_images(full=True)\n",
    "        images = []\n",
    "        for img in img_list:\n",
    "            img_path = save_image(doc, img, page_number)\n",
    "            # Approximate y position (center y)\n",
    "            y_pos = (page.rect.height / 2)  # fallback\n",
    "            images.append((img_path, y_pos))\n",
    "\n",
    "        chunks = create_chunks_from_page(block_info, images, page_number)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_id = f\"page_{page_number}_chunk_{i}_{uuid.uuid4().hex[:6]}\"\n",
    "            chunk[\"id\"] = chunk_id\n",
    "            chunk[\"page\"] = page_number\n",
    "            all_chunks.append(chunk)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, \"chunks.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_chunks, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_store_chunks(chunks):\n",
    "    docs = []\n",
    "    for chunk in chunks:\n",
    "        content = chunk[\"text\"]\n",
    "        if chunk.get(\"image_caption\"):\n",
    "            content += f\"\\n[Hình ảnh]: {chunk['image_caption']}\"\n",
    "        if chunk.get(\"table\"):\n",
    "            content += f\"\\n[Bảng]: {chunk['table']}\"\n",
    "\n",
    "        metadata = {\n",
    "                \"chunk_id\": chunk[\"id\"],\n",
    "                \"page\": chunk[\"page\"],\n",
    "        }\n",
    "\n",
    "        # Chỉ thêm image_path nếu khác None\n",
    "        if chunk.get(\"image_path\") is not None:\n",
    "            metadata[\"image_path\"] = str(chunk[\"image_path\"])\n",
    "\n",
    "        docs.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "    embedder = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "    vectordb = Chroma.from_documents(docs, embedder, persist_directory=CHROMA_DB_DIR)\n",
    "    vectordb.persist()\n",
    "    print(\"✅ Vectorstore saved to:\", CHROMA_DB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorstore saved to: chroma_db\n",
      "✅ Total chunks: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSII\\AppData\\Local\\Temp\\ipykernel_3812\\940284113.py:23: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "chunks = process_pdf(PDF_PATH)\n",
    "embed_and_store_chunks(chunks)\n",
    "print(f\"✅ Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
